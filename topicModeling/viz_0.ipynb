{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/anaconda3/envs/nlp/lib/python3.9/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "import re\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import tomotopy as tp\n",
    "import pyLDAvis\n",
    "import pandas as pd\n",
    "import tmplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../sampleData/tripadvisorReviews/hotel_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  nice hotel expensive parking got good deal sta...       4\n",
       "1  ok nothing special charge diamond member hilto...       2\n",
       "2  nice rooms not 4* experience hotel monaco seat...       3\n",
       "3  unique, great stay, wonderful time hotel monac...       5\n",
       "4  great stay great stay, went seahawk game aweso...       5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = nltk.PorterStemmer().stem\n",
    "english_stops = set(porter_stemmer(w) for w in stopwords.words('english'))\n",
    "pat = re.compile('^[a-z]{2,}$')\n",
    "corpus = tp.utils.Corpus(\n",
    "    tokenizer=tp.utils.SimpleTokenizer(porter_stemmer), \n",
    "    stopwords=lambda x: x in english_stops or not pat.match(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20491"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = df['Review'].tolist()\n",
    "corpus.process(doc.lower() for doc in reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num docs:20491, Num Vocabs:9545, Total Words:1445015\n",
      "Removed Top words:  hotel room stay great good staff night locat nice day time clean servic restaur beach walk breakfast place food like resort pool help bed realli love area friendli peopl excel book bar want small recommend littl got view bathroom look\n"
     ]
    }
   ],
   "source": [
    "mdl = tp.LDAModel(min_df=5, rm_top=40, k=9, corpus=corpus)\n",
    "mdl.train(0)\n",
    "\n",
    "print('Num docs:{}, Num Vocabs:{}, Total Words:{}'.format(\n",
    "    len(mdl.docs), len(mdl.used_vocabs), mdl.num_words\n",
    "))\n",
    "print('Removed Top words: ', *mdl.removed_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0000, LL per word: -10.18\n",
      "Iteration: 0020, LL per word: -8.537\n",
      "Iteration: 0040, LL per word: -8.34\n",
      "Iteration: 0060, LL per word: -8.275\n",
      "Iteration: 0080, LL per word: -8.24\n",
      "Iteration: 0100, LL per word: -8.217\n",
      "Iteration: 0120, LL per word: -8.201\n",
      "Iteration: 0140, LL per word: -8.19\n",
      "Iteration: 0160, LL per word: -8.185\n",
      "Iteration: 0180, LL per word: -8.177\n",
      "Iteration: 0200, LL per word: -8.171\n",
      "Iteration: 0220, LL per word: -8.169\n",
      "Iteration: 0240, LL per word: -8.168\n",
      "Iteration: 0260, LL per word: -8.165\n",
      "Iteration: 0280, LL per word: -8.163\n",
      "Iteration: 0300, LL per word: -8.16\n",
      "Iteration: 0320, LL per word: -8.159\n",
      "Iteration: 0340, LL per word: -8.158\n",
      "Iteration: 0360, LL per word: -8.157\n",
      "Iteration: 0380, LL per word: -8.153\n",
      "Iteration: 0400, LL per word: -8.152\n",
      "Iteration: 0420, LL per word: -8.148\n",
      "Iteration: 0440, LL per word: -8.146\n",
      "Iteration: 0460, LL per word: -8.144\n",
      "Iteration: 0480, LL per word: -8.14\n",
      "Iteration: 0500, LL per word: -8.139\n",
      "Iteration: 0520, LL per word: -8.138\n",
      "Iteration: 0540, LL per word: -8.137\n",
      "Iteration: 0560, LL per word: -8.136\n",
      "Iteration: 0580, LL per word: -8.136\n",
      "Iteration: 0600, LL per word: -8.133\n",
      "Iteration: 0620, LL per word: -8.131\n",
      "Iteration: 0640, LL per word: -8.13\n",
      "Iteration: 0660, LL per word: -8.13\n",
      "Iteration: 0680, LL per word: -8.129\n",
      "Iteration: 0700, LL per word: -8.128\n",
      "Iteration: 0720, LL per word: -8.128\n",
      "Iteration: 0740, LL per word: -8.128\n",
      "Iteration: 0760, LL per word: -8.126\n",
      "Iteration: 0780, LL per word: -8.122\n",
      "Iteration: 0800, LL per word: -8.121\n",
      "Iteration: 0820, LL per word: -8.123\n",
      "Iteration: 0840, LL per word: -8.123\n",
      "Iteration: 0860, LL per word: -8.121\n",
      "Iteration: 0880, LL per word: -8.124\n",
      "Iteration: 0900, LL per word: -8.125\n",
      "Iteration: 0920, LL per word: -8.124\n",
      "Iteration: 0940, LL per word: -8.122\n",
      "Iteration: 0960, LL per word: -8.122\n",
      "Iteration: 0980, LL per word: -8.123\n",
      "Iteration: 1000, LL per word: -8.121\n",
      "<Basic Info>\n",
      "| LDAModel (current version: 0.12.2)\n",
      "| 20491 docs, 1445015 words\n",
      "| Total Vocabs: 35121, Used Vocabs: 9545\n",
      "| Entropy of words: 7.56949\n",
      "| Entropy of term-weighted words: 7.56949\n",
      "| Removed Vocabs: hotel room stay great good staff night locat nice day time clean servic restaur beach walk breakfast place food like resort pool help bed realli love area friendli peopl excel book bar want small recommend littl got view bathroom look\n",
      "|\n",
      "<Training Info>\n",
      "| Iterations: 1000, Burn-in steps: 0\n",
      "| Optimization Interval: 10\n",
      "| Log-likelihood per word: -8.12107\n",
      "|\n",
      "<Initial Parameters>\n",
      "| tw: TermWeight.ONE\n",
      "| min_cf: 0 (minimum collection frequency of words)\n",
      "| min_df: 5 (minimum document frequency of words)\n",
      "| rm_top: 40 (the number of top words to be removed)\n",
      "| k: 9 (the number of topics between 1 ~ 32767)\n",
      "| alpha: [0.1] (hyperparameter of Dirichlet distribution for document-topic, given as a single `float` in case of symmetric prior and as a list with length `k` of `float` in case of asymmetric prior.)\n",
      "| eta: 0.01 (hyperparameter of Dirichlet distribution for topic-word)\n",
      "| seed: 2713601441 (random seed)\n",
      "| trained in version 0.12.2\n",
      "|\n",
      "<Parameters>\n",
      "| alpha (Dirichlet prior on the per-document topic distributions)\n",
      "|  [0.28302783 0.31741038 0.3444989  0.4281185  0.27413544 0.15045084\n",
      "|   0.24169792 0.5404709  0.09671653]\n",
      "| eta (Dirichlet prior on the per-topic word distribution)\n",
      "|  0.01\n",
      "|\n",
      "<Topics>\n",
      "| #0 (323103) : drink water buffet beauti vacat\n",
      "| #1 (150860) : coffe shower floor tv larg\n",
      "| #2 (190595) : check arriv desk told ask\n",
      "| #3 (201469) : bad star floor better review\n",
      "| #4 (128837) : citi station minut euro barcelona\n",
      "| #5 (70414) : pari street florenc close quiet\n",
      "| #6 (120722) : park car price street san\n",
      "| #7 (207844) : wonder best beauti return fantast\n",
      "| #8 (51171) : bali shop harbour club sydney\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 1000, 20):\n",
    "    print('Iteration: {:04}, LL per word: {:.4}'.format(i, mdl.ll_per_word))\n",
    "    mdl.train(20)\n",
    "print('Iteration: {:04}, LL per word: {:.4}'.format(1000, mdl.ll_per_word))\n",
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_dists = np.stack([mdl.get_topic_word_dist(k) for k in range(mdl.k)])\n",
    "doc_topic_dists = np.stack([doc.get_topic_dist() for doc in mdl.docs])\n",
    "doc_topic_dists /= doc_topic_dists.sum(axis=1, keepdims=True)\n",
    "doc_lengths = np.array([len(doc.words) for doc in mdl.docs])\n",
    "vocab = list(mdl.used_vocabs)\n",
    "term_frequency = mdl.used_vocab_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/anaconda3/envs/nlp/lib/python3.9/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "/home/simone/anaconda3/envs/nlp/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/simone/anaconda3/envs/nlp/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/simone/anaconda3/envs/nlp/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/simone/anaconda3/envs/nlp/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/simone/anaconda3/envs/nlp/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "prepared_data = pyLDAvis.prepare(\n",
    "    topic_term_dists, \n",
    "    doc_topic_dists, \n",
    "    doc_lengths, \n",
    "    vocab, \n",
    "    term_frequency,\n",
    "    start_index=0, \n",
    "    sort_topics=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(prepared_data, 'ldavis.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3198774d478c92d6e1ad3a290c11f1e70354ee6bb5c8401b09dc4dd7ec0758c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
